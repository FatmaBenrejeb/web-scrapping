from bs4 import BeautifulSoup
import requests
import pandas as pd

p = requests.get("https://mbasic.facebook.com/SocieteTunisiennedeBanquePageOfficielle/")
soup = BeautifulSoup(p.content,'html.parser')



publications=[]

res=soup.find('div',attrs={'id':'structured_composer_async_container'})
a=res.find_all('a')
#print(a)
for i in a:
    link=i.get('href')
    if(link.startswith('/SocieteTunisiennedeBanquePageOfficielle/photos/a.')):
        #print(link) 
        #pub_link='https://mbasic.facebook.com'+link
        #print(pub_link)
        #OKKK!!!! lien de chaque publication
        publications.append(link)
#print(publications)

path = r"C:\Users\HP\stbPubfinal.xlsx"
writer = pd.ExcelWriter(path, engine = 'xlsxwriter')  

df=pd.DataFrame({'lien_publication':publications})
df.to_excel(writer, sheet_name = 'Liste_publications')

n=0

for pub in publications:
    page= requests.get('https://mbasic.facebook.com'+pub)
    sp = BeautifulSoup(page.text,'html.parser')

    user_name=[]
    user_name_url=[]
    user_name_list = sp.find_all('h3')
    user_comment=[]
    user_comment_list = sp.find_all('div',attrs={'class':'_14ye'})
    #print(user_name_list) #OK!!!
    print(pub)
    print("###########")
    for user in user_name_list:
        user_name.append(user.find('a').text)
        user_name_url.append(user.find('a').get('href')) #OKKKK!!!!!!!
    #print(user_name_url) #OK!!
    print(user_name) #OK!!

    for comment in user_comment_list:
        #print(comment.text)
        user_comment.append(comment.text)
    #print(user_comment) #OK!!

    df3 = pd.DataFrame({'User Name':user_name,'User_fb_url':user_name_url,'Comment':user_comment})
    df3.to_excel(writer, sheet_name = 'pub N'+str(n))
    n=n+1

writer.save()
writer.close()
